<!DOCTYPE HTML>
<html>
    <head>
        <title>Shuran Song</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />

        <script>
             (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
             m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
             ga('create', 'UA-89797207-1', 'auto');
             ga('send', 'pageview');
       </script>
    </head>
    <body id="body">
        <div id="main"> 
            <header id="header">
                <a href="index.html">HOME</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="https://real.stanford.edu/">LAB</a>
            </header>
            <div id="profile">
                <div id="profile-pic">
                    <img src="images/people/shuran_song.jpg">
                    <p>
                        <a href="https://scholar.google.com/citations?hl=en&user=5031vK4AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://twitter.com/SongShuran">Twitter</a>
                    </p>
                </div>
                <div id="profile-intro">
                    <div id="profile-name">Shuran Song</div>
                    <p>
                        Assistant Professor of Electrical Engineering, by courtesy, of Computer Science at <a href="http://stanford.edu/"> Stanford University</a> <br>

                        <!-- Adjunct Professor of Computer Science at <a href="http://www.cs.columbia.edu/"> Columbia University</a> <br> <br>  
 -->
                        I lead the Robotics and Embodied AI Lab at Stanford University(<a href="https://real.stanford.edu/"> REAL@Stanford </a>).  We are interested in developing algorithms that enable intelligent systems to learn from their interactions with the physical world, and autonomously acquire the perception and manipulation skills necessary to execute complex tasks and assist people. 
                    
                        To learn more about my group's research please visit our <a href="https://real.stanford.edu/"> REAL website</a>.
                    <p>
                        Email: shuran [at] stanford [dot] edu <br> 
                        Office: RM258, 350 Jane Stanford Way Packard Bldg Stanford, CA 94305. 
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            <div class="section recent-work">
                <div class="slider">
                  
                  <a href="http://diffusion-policy.cs.columbia.edu/"><img src="images/projects/diffusion.gif"></a>
                  <a href="http://dextairity.cs.columbia.edu/"><img src="images/projects/air.gif"></a>
                    <a href="http://irp.cs.columbia.edu/"><img src="images/projects/irp.jpeg"></a>
                    <a href="http://flingbot.cs.columbia.edu/"><img src="https://flingbot.cs.columbia.edu/images/teaser.png"></a>
                    <a href="http://dsr-net.cs.columbia.edu/"><img src="images/projects/dsr.gif"></a>
                    <!-- <a href="http://graspinwild.cs.columbia.edu/"><img src="images/projects/graspinwild.jpg"></a> -->
                    <!-- <a href="http://form2fit.github.io/"><img src="images/projects/form2fit.png"></a> -->
                    <a href="https://tossingbot.cs.princeton.edu/"><img src="images/projects/tossingbot.png"></a>
                    <!-- <a href="https://sites.google.com/view/cleargrasp"><img src="images/projects/cleargrasp.gif"></a> -->
                    <!--  <a href="https://spatial-action-maps.cs.princeton.edu/"><img src="images/projects/sam.png"></a> -->
                </div>
            </div>

            <div class="divider"></div>
<!--             <div class="section">
                <h1>News</h1>
                <p>
                    <ul>
                      
                      <li><a href="https://irp.cs.columbia.edu/">IRP</a> won <a href="https://roboticsconference.org/program/awards/"> Best Paper Award </a> at RSS 2022!
                        <li><a href="https://dextairity.cs.columbia.edu/">DextAIRity</a> get selected as <a href="https://roboticsconference.org/program/awards/"> Best System Paper Finalist </a> at RSS 2022!


                        <li> Received a <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2143601&HistoricalAwards=false"> NSF CAREER award </a> </li>

                        <li> Honored to be a <a href="https://sloan.org/fellowships/2022-Fellows"> 2022 Sloan Research Fellow </a> </li>
                        <li><a href="https://flingbot.cs.columbia.edu/">FlingBot</a> won <a href="https://sites.google.com/robot-learning.org/corl2021/program/awards_2021?authuser=0"> Best System Paper Award at CoRL</a> 2021!
                    	<li> Honored to be a <a href="https://www.microsoft.com/en-us/research/academic-program/faculty-fellowship/#!fellows"> 2021 Microsoft Research Faculty Fellow </a> </li>
                    	<li> TossingBot won <a href="https://www.ieee-ras.org/publications/t-ro"> 2020 IEEE Transactions on Robotics Best Paper Award! </a> </li>
                        
                        
                        <span id="moreNews">
                        <li><a href="https://form2fit.github.io/">  Form2Fit </a> got ICRA'20 <a href="https://form2fit.github.io/"> Best Paper in Automation </a> Award Finalist </li>
                        <li><a href="https://illumination.cs.princeton.edu/"> Nerual Illumination </a> got CVPR'19 <a href="https://illumination.cs.princeton.edu/">Best Paper </a> Award Finalist</li>
                        <li> <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/faculty-research-awards-2021">  JP Morgan Faculty Research Award </a> 2021 </li>
                        <li> <a href="https://www.tri.global/news/university-collab/"> TRI Young Faculty Award  </a> 2021</li>
                        <li> <a href="https://www.amazon.science/research-awards/recipients"> Amazon Research Award  </a> 2020 </li>
                        <li><a href="https://tossingbot.cs.princeton.edu/"> TossingBot </a> got RSS'19 <a href="https://tossingbot.cs.princeton.edu/">Best Systems Paper</a> Award and featured on the front page of <a href="images/nytimes-business-newspaper-tossingbot.png">The New York Times Business</a></li></li>  
                        <li><a href="https://vpg.cs.princeton.edu/">Learning Synergies between Pushing and Grasping</a>  got IROS <a href="http://vpg.cs.princeton.edu/">Best Cognitive Robotics Paper</a> Award Finalist</li>
                        <li>Amazon Robotics <a href="http://arc.cs.princeton.edu">Best Systems Paper</a> Award</li>
                        <li>1<sup>st</sup> place winners of the stow task at the worldwide <a href="https://www.amazonrobotics.com/">Amazon Picking Challenge</a> with <a href="https://mcube.mit.edu/">MIT</a></li>
                        </span>
                        <div onclick="toggleNews()" id="moreNewsBtn" class="showBtn"><a>Show more...</a></div>
                        <div onclick="toggleNews()" id="lessNewsBtn" class="showBtn"><a>Show less...</a></div>
                    </ul>
                </p>
                <div style="clear: both;"></div>
            </div>
            <div class="divider"></div> -->
            
            <div class="section">
                <h1>Recent Talks</h1>
                <p>
                    <ul>
                        <li> What I wish I had for Robot Learning 
                        (<a href="https://www.dropbox.com/scl/fi/obcik2tpg7py3i86yczrv/CoRL23_conference.pdf?rlkey=bunk5ptmwjbdqclwe47jnkl8b&dl=0"> Slides </a>)   Early Career Keynote at <a href="https://www.corl2023.org/speakers">Conference on Robot Learning </a> </li>

                        <li> Learning Meets Gravity: Robots that Embrace Dynamics and Pixels
                        (<a href="https://www.ri.cmu.edu/event/learning-meets-gravity-robots-that-learn-to-embrace-dynamics-from-data/"> Talk </a>)  at CMU Robotics Institute</li>

                        <li> Abstraction as Inductive Bias: Open-World 3D Scene Understanding without Open-World 3D Data 
                        (<a href="https://www.cs.columbia.edu/~shurans/talks/CoRL_inductive_bias.pdf"> Slide </a>)  at <a href="https://sites.google.com/view/corl-2022-inductive-bias-ws/home?authuser=0">  Inductive Bias in Robot Learning Workshop</a> @ CoRL'22</li>

                        <li> The Reasonable Effectiveness of Dynamic Manipulation for Deformable Objects(<a href="https://www.youtube.com/watch?v=Pia-V67ishw&ab_channel=UniversityofTorontoRoboticsInstitute"> Talk </a>)  at University of Toronto Robotics Institute  </li>


                        <li> Structure from Action: Articulated Object Structure Discovery with Active Interactions (<a href="https://www.cs.columbia.edu/~shurans/talks/StrcturefromAction.pdf"> Slides </a>)  at ICCV <a href="https://geometry.stanford.edu/struco3d/"> Struco3D Workshop </a>  </li>
                        <li> Self-Adaptive Manipulation  (<a href="https://www.cs.columbia.edu/~shurans/talks/self-adaptive-grasping.pdf"> Slides </a>)  (<a href="https://www.youtube.com/watch?v=f2OZPwhSQu4&ab_channel=AllenInstituteforAI"> Talk </a>)  </li>
                    	<li>Unfolding the Unseen: Deformable Cloth Perception and Manipulation  (<a href="https://www.cs.columbia.edu/~shurans/talks/unfold_unsceen.m4v"> Slides Video </a> <a href="https://www.cs.columbia.edu/~shurans/talks/Cloth_Precpetion.pdf"> PDF</a>)  (<a href="https://www.youtube.com/watch?v=Ek20Zw77QPU&ab_channel=3DGVSeminar"> Talk </a>)  </li>
                        <li>Active Scene Understanding with Robot Interactions (<a href="https://www.cs.columbia.edu/~shurans/talks/2020_active_scene.pdf"> Slides </a>)  </li>
                        
                        <span id="moreTalks">
                        <li>Category-level Pose Estimation (<a href="https://www.cs.columbia.edu/~shurans/talks/Pose_Estimation_ECCV_2020.pdf"> Slides </a>) at ECCV2020  <a href="http://cmp.felk.cvut.cz/sixd/workshop_2020/">  Workshop on Recovering 6D Object Pose </a></li>
                        <li>Learning Visual Representations for Generalizable Manipulation  (<a href="https://www.cs.columbia.edu/~shurans/talks/visualrep_manuplation_cvpr2020.pdf"> Slides </a>) at CVPR2020 <a href="https://scene-understanding.com/">  3D Scene Understanding for Vision, Graphics, and Robotics </a></li>
                        </span>

                        <div onclick="toggleTalks()" id="moreTalksBtn" class="showBtn"><a>Show more...</a></div>
                        <div onclick="toggleTalks()" id="lessTalksBtn" class="showBtn"><a>Show less...</a></div>
                        
                    </ul>
                </p>
                <div style="clear: both;"></div>
            </div>

            <div class="divider"></div>
            <div class="section research">
                <h1>Publications</h1>

                <h3><div id="repBtn"><a href="javascript:showRep()">Representative</a></div>&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp;&nbsp;<div id="showAllBtn"><a href="javascript:hideRep()">See All Publications</a></div></h3>



                <div class="research-proj">
                    <a href="https://project-roco.github.io/" class="research-thumb">
                    <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="images/projects/umi_thumbnail.mp4" type="video/mp4">
                    </video>
                    </a>


                    <a href="https://umi-gripper.github.io/" class="research-proj-title">  Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots </a>
                    <p> Cheng Chi*, Zhenjia Xu*, Chuer Pan, Eric Cousineau, Ben Burchfiel, Siyuan Feng, Russ Tedrake, Shuran Song <br>
                       ArXiv preprint <br>
                       <a href="https://umi-gripper.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2402.10329">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://umi-gripper.github.io/">Code </a> 
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://project-roco.github.io/" class="research-thumb">
                    <img src="images/projects/roco-teaser-gif.gif" alt="" />
                    </a>


                    <a href="https://project-roco.github.io/" class="research-proj-title">  RoCo: Dialectic Multi-Robot Collaboration with Large Language Models </a>
                    <p> Zhao Mandi, Shreeya Jain, Shuran Song <br>
                       International Conference on Robotics and Automation  (<b>ICRA 2023</b>)<br>
                       <a href="https://project-roco.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2307.04738">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://project-roco.github.io/">Code </a> 
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://robotics-transformer-x.github.io/" class="research-thumb">
                    <img src="images/projects/RT-x.png" alt="" />
                    </a>


                    <a href="https://robotics-transformer-x.github.io/" class="research-proj-title">  Open X-Embodiment: Robotic Learning Datasets and RT-X Models</a>
                    <p> Abhishek Padalkar et al <br>
                       International Conference on Robotics and Automation (ICRA 2024) <br>
                       <a href="https://robotics-transformer-x.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/pdf/2310.08864.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://robotics-transformer-x.github.io/">Code </a> 
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://datacomp.ai/" class="research-thumb">
                    <img src="images/projects/datacomp.png" alt="" />
                    </a>

                    <a href="https://arxiv.org/abs/2304.14108" class="research-proj-title">  DataComp: In search of the next generation of multimodal datasets </a>
                    <p> Samir Yitzhak Gadre*, Gabriel Ilharco*, Alex Fang* et al. <br>
                       NeurIPS, 2023 (oral) <br>
                       <a href="https://datacomp.ai/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2304.14108">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/mlfoundations/datacomp">Code </a> 
                    </p>
                    <p> <br> </p>
                </div>

                
                <div class="research-proj">
                    <a href="https://www.cs.columbia.edu/~huy/scalingup/" class="research-thumb">

                    <video playsinline="" muted="" autoplay="" loop="" width="180px">
                        <source src="images/projects/scalingup-teaser.mp4" type="video/mp4">
                    </video>
                    </a>

                    
              

                    <a href="https://www.cs.columbia.edu/~huy/scalingup/" class="research-proj-title">  Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition </a>
                    <p> Huy Ha, Pete Florence, Shuran Song <br>
                       Conference on Robot Learning 2023 <br>
                       <a href="https://www.cs.columbia.edu/~huy/scalingup/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2307.14535">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/columbia-ai-robotics/scalingup">Code </a> 
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://robot-reflect.github.io/" class="research-thumb">
                    
                    <img src="images/projects/reflect.png" alt="" />
                    <a href="https://robot-reflect.github.io/" class="research-proj-title">  REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction </a>
                    <p>
                       Zeyi Liu*, Arpit Bahety*, Shuran Song 
                       <br>
                       Conference on Robot Learning 2023 <br>
                       <a href="https://robot-reflect.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2306.15724">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/columbia-ai-robotics/reflect">Code </a> 
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://xskillcorl.github.io/" class="research-thumb">
                    <img src="images/projects/Xskill.png" alt="" />
                    <a href="https://xskillcorl.github.io/" class="research-proj-title">  XSkill: Cross Embodiment Skill Discovery </a>
                    <p>
                        Mengda Xu, Zhenjia Xu, Cheng Chi, Manuela Veloso, Shuran Song
                       <br>
                       Conference on Robot Learning 2023 <br>
                       <a href="https://xskillcorl.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2307.09955">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://xskillcorl.github.io/">Code </a> 
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://general-part-assembly.github.io/" class="research-thumb">
                    <img src="images/projects/GPAT.jpeg" alt="" />
                    <a href="https://general-part-assembly.github.io/" class="research-proj-title">  Rearrangement Planning for General Part Assembly </a>
                    <p>
                       Yulong Li, Andy Zeng, Shuran Song
                       <br>
                       Conference on Robot Learning 2023 <br>
                       <strong>Oral Presentation</strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://general-part-assembly.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/pdf/2307.00206.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://general-part-assembly.github.io/">Code </a> 
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://tidybot.cs.princeton.edu/" class="research-thumb"><img src="images/projects/wu2023tidybot.gif" alt="" /></a>
                    <a href="https://tidybot.cs.princeton.edu/" class="research-proj-title">  TidyBot: Personalized Robot Assistance with Large Language Models </a>
                    <p>
                       Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser<br>
                       Autonomous Robots (AuRo) - Special Issue: Large Language Models in Robotics, 2023 <br>
                       IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023 <br>
                       <a href="https://tidybot.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2305.05658">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/jimmyyhwu/tidybot">Code</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://sfa.cs.columbia.edu/" class="research-thumb"><img src="images/projects/sfa.png" alt="" /></a>
                    <a href="https://sfa.cs.columbia.edu/" class="research-proj-title"> Structure From Action: Learning Interactions for Articulated Object 3D Structure Discovery </a>
                    <p>
                       Neil Nie, Samir Yitzhak Gadre, Kiana Ehsani, Shuran Song <br>
                       IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023 <br>
                       <a href="https://sfa.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2207.08997">Paper</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://bag-all-you-need.cs.columbia.edu/" class="research-thumb"><img src="images/projects/bag.png" alt="" /></a>
                    <a href="https://bag-all-you-need.cs.columbia.edu/" class="research-proj-title"> Bag All You Need: Learning a Generalizable Bagging Strategy for Heterogeneous Objects </a>
                    <p>
                       Arpit Bahety*, Shreeya Jain*, Huy Ha, Nathalie Hager, Benjamin Burchfiel, Eric Cousineau, Siyuan Feng, Shuran Song <br>
                       IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023 <br>
                       <a href="https://bag-all-you-need.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2210.09997">Paper</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://diffusion-policy.cs.columbia.edu/" class="research-thumb"><img src="images/projects/diffusion.gif" alt="" /></a>
                    <a href="https://diffusion-policy.cs.columbia.edu/" class="research-proj-title"> Diffusion Policy: Visuomotor Policy Learning via Action Diffusion </a>
                    <p>
                       Cheng Chi,  Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, Shuran Song<br>
                       Robotics: Science and Systems (RSS)  2023<br>
                       <a href="https://diffusion-policy.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://diffusion-policy.cs.columbia.edu/">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                       <a href="https://github.com/columbia-ai-robotics/diffusion_policy">Code</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://roboninja.cs.columbia.edu/" class="research-thumb"><img src="images/projects/RoboNinja_RSS.gif" alt="" /></a>
                    <a href="https://roboninja.cs.columbia.edu/" class="research-proj-title"> RoboNinja: Learning an Adaptive Cutting Policy for Multi-Material Objects </a>
                    <p>
                       Zhenjia Xu, Zhou Xian, Xingyu Lin, Cheng Chi, Zhiao Huang, Chuang Gan, Shuran Song<br>
                       Robotics: Science and Systems (RSS)  2023 <br>
                       <a href="https://roboninja.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2302.11553">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                       <a href="https://github.com/columbia-ai-robotics/roboninja">Code & Simulation </a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://cow.cs.columbia.edu/" class="research-thumb"><img src="images/projects/cow.png" alt="" /></a>
                    <a href="https://cow.cs.columbia.edu/" class="research-proj-title">CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation <br> (a.k.a Clip on Wheels) </a>
                    <p>
                       Samir Yitzhak Gadre, Mitchell Wortsman, Gabriel Ilharco, Ludwig Schmidt, Shuran Song <br>
                       Conference on Computer Vision and Pattern Recognition (CVPR 2022) <br>
                       <a href="https://cow.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2203.10421">Paper</a>
<!--                        &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="">Code Coming Soon</a> -->
                       
                    </p>
                </div>



                <div class="research-proj">
                    <a href="https://clothfunnels.cs.columbia.edu/" class="research-thumb"><img src="images/projects/funnel.png" alt="" /></a>
                    <a href="https://clothfunnels.cs.columbia.edu/" class="research-proj-title"> Cloth Funnels: Canonicalized-Alignment for Multi-Purpose Garment Manipulation </a>
                    <p>
                       Alper Canberk, Cheng Chi, Huy Ha, Benjamin Burchfiel, Eric Cousineau, Siyuan Feng, Shuran Song<br>
                       International Conference on Robotics and Automation  (<b>ICRA 2023</b>)<br>
                       <a href="https://clothfunnels.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2210.09347">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                    </p>
                </div>




                <div class="research-proj">
                    <a href="https://jxu.ai/tandem3d/" class="research-thumb"><img src="images/projects/touch3d.png" alt="" /></a>
                    <a href="https://jxu.ai/tandem3d/" class="research-proj-title"> TANDEM3D: Active Tactile Exploration for 3D Object Recognition </a>
                    <p>
                       Jingxi Xu*, Han Lin*, Shuran Song, Matei Ciocarlie <br>
                       International Conference on Robotics and Automation  (<b>ICRA 2023</b>)<br>
                       <a href="https://jxu.ai/tandem3d/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2209.08772">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://semantic-abstraction.cs.columbia.edu/" class="research-thumb"><img src="images/projects/semabs-rect.gif" alt="" /></a>
                    <a href="https://semantic-abstraction.cs.columbia.edu/" class="research-proj-title"> Semantic Abstraction: Open-World 3D Scene Understanding from 2D Vision-Language Models </a>
                    <p>
                       Huy Ha, Shuran Song <br>
                       Conference on Robot Learning (<b>CoRL2022</b>)<br>
                       <a href="https://semantic-abstraction.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/pdf/2207.11514.pdf">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                       <a href="https://github.com/columbia-ai-robotics/semantic-abstraction">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                       <a href="https://huggingface.co/spaces/huy-ha/semabs-relevancy">Demo on Huggingface</a>
                       
                    </p>
                </div>

                

                <div class="research-proj">
                    <a href="https://busybot.cs.columbia.edu/" class="research-thumb"><img src="images/projects/busybot.gif" alt="" /></a>
                    <a href="https://busybot.cs.columbia.edu/" class="research-proj-title"> BusyBot: Learning to Interact, Reason, and Plan in a BusyBoard Environment </a>
                    <p>
                       Zeyi Liu, Zhenjia Xu, Shuran Song <br>
                       Conference on Robot Learning (<b>CoRL2022</b>)<br>
                       <a href="https://busybot.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2207.08192">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                       <a href="https://github.com/columbia-ai-robotics/BusyBot">Code</a>  
                       
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://aspire.cs.columbia.edu/" class="research-thumb"><img src="images/projects/aspire.png" alt="" /></a>
                    <a href="https://aspire.cs.columbia.edu/" class="research-proj-title"> ASPiRe: Adaptive Skill Priors for Reinforcement Learning </a>
                    <p>
                        Mengda Xu, Manuela Veloso, Shuran Song <br>
                        Conference on Neural Information Processing Systems (NeurIPS 2022) <br>
                       <a href="https://aspire.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://aspire.cs.columbia.edu/">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; 
                       <a href="https://github.com/columbia-ai-robotics/ASPiRe">Code</a>  
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://model-patching.github.io/" class="research-thumb"><img src="images/projects/paint.jpeg" alt="" /></a>
                    <a href="https://model-patching.github.io/" class="research-proj-title"> Patching open-vocabulary models by interpolating weights </a>
                    <p>
                        Gabriel Ilharco*, Mitchell Wortsman*, Samir Yitzhak Gadre*, Shuran Song, Hannaneh Hajishirzi Simon Kornblith, Ali Farhadi, Ludwig Schmidt <br>
                        Conference on Neural Information Processing Systems (NeurIPS 2022) <br>
                       <a href="https://model-patching.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2208.05592">Paper</a>
                       &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/mlfoundations/patching">Code</a>
                       
                    </p>
                </div>

                <!-- <div class="research-proj">
                    <a href="https://cow.cs.columbia.edu/" class="research-thumb"><img src="images/projects/cow.png" alt="" /></a>
                    <a href="https://cow.cs.columbia.edu/" class="research-proj-title">CLIP on Wheels: Open-Vocabulary Models are (Almost) Zero-Shot Object Navigators</a>
                    <p>
                       Samir Yitzhak Gadre, Mitchell Wortsman, Gabriel Ilharco, Ludwig Schmidt, Shuran Song <br>
                       Arxiv Preprint <br>
                       <a href="https://cow.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2203.10421">Paper</a>
                       &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="">Code Coming Soon</a>
                       
                    </p>
                </div> -->

                
                


                <div class="research-proj">
                    <a href="https://irp.cs.columbia.edu/" class="research-thumb"><img src="images/projects/irp.jpeg" alt="" /></a>
                    <a href="https://irp.cs.columbia.edu/" class="research-proj-title">Iterative Residual Policy for Goal-Conditioned Dynamic Manipulation of Deformable Objects</a>
                    <p>
                       Cheng Chi, Benjamin Burchfiel, Eric Cousineau, Siyuan Feng, Shuran Song <br>
                       Robotics: Science and Systems (RSS)  2022 <br>
                       <strong>Best Paper Award</strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                      <strong>Best Student Paper Finalist</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://irp.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2203.00663">Paper</a>
                       &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/columbia-ai-robotics/irp">Code</a>
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://dextairity.cs.columbia.edu/" class="research-thumb"><img src="images/projects/air.gif" alt="" /></a>
                    <a href="https://dextairity.cs.columbia.edu/" class="research-proj-title">DextAIRity: Deformable Manipulation Can be a Breeze</a>
                    <p>
                       Zhenjia Xu, Cheng Chi, Benjamin Burchfiel, Eric Cousineau, Siyuan Feng, Shuran Song <br>
                       Robotics: Science and Systems (RSS)  2022 <br>
                       <strong>Best System Paper Finalist</strong>  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://dextairity.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2203.01197">Paper</a>
                       &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/columbia-ai-robotics/dextairity">Code</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://learning-dynamic-manipulation.cs.princeton.edu/" class="research-thumb"><img src="images/projects/air-wu.gif" alt="" /></a>
                    <a href="https://learning-dynamic-manipulation.cs.princeton.edu/" class="research-proj-title">Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower</a>
                    <p>
                       Jimmy Wu, Xingyuan Sun, Andy Zeng, Shuran Song, Szymon Rusinkiewicz, Thomas Funkhouser <br>
                       Robotics and Automation Letters (RA-L) 2022</i><br> Intelligent Robots and Systems (IROS) 2022 <br> 
                       <a href="https://learning-dynamic-manipulation.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2204.02390">Paper</a>
                       &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/jimmyyhwu/learning-dynamic-manipulation">Code</a>
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://jxu.ai/tandem/" class="research-thumb"><img src="images/projects/tandem.jpeg" alt="" /></a>
                    <a href="https://jxu.ai/tandem/" class="research-proj-title">TANDEM: Learning Joint Exploration and Decision Making with Tactile Sensors </a>
                    <p>
                       Jingxi Xu, Shuran Song, Matei Ciocarlie <br>
                       Robotics and Automation Letters (RA-L) 2022</i><br> Intelligent Robots and Systems (IROS) 2022 <br> 
                       <a href="https://jxu.ai/tandem/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2203.00798">Paper</a>
                       <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/columbia-ai-robotics/">Code</a> -->
                       
                    </p>
                </div>

                 <div class="research-proj">
                    <a href="https://seat.cs.columbia.edu/" class="research-thumb"><img src="images/projects/seat.jpeg" alt="" /></a>
                    <a href="https://seat.cs.columbia.edu/" class="research-proj-title">Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly</a>
                    <p>
                       Shubham Agrawal*, Yulong Li*, Jen-Shuo Liu, Steven K. Feiner, Shuran Song <br>
                       Intelligent Robots and Systems (IROS) 2022 <br> 
                       <a href="https://seat.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2110.04450">Paper</a>
                       <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/columbia-ai-robotics/">Code</a> -->
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://prior.allenai.org/projects/csr" class="research-thumb"><img src="images/projects/CSR.jpeg" alt="" /> </a>
                    <a href="https://prior.allenai.org/projects/csr" class="research-proj-title">Continuous Scene Representations for Embodied AI</a>
                    <p>
                       Samir Yitzhak Gadre, Kiana Ehsani, Shuran Song, Roozbeh Mottaghi, <br>
                       Proceedings of IEEE Conference on Computer Vision and Pattern Recognition <b> (CVPR 2022) <b> <br>
                       <a href="https://prior.allenai.org/projects/csr">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2203.17251">Paper</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://ump-net.cs.columbia.edu/" class="research-thumb"><img src="images/projects/ump-net.jpeg" alt="" /></a>
                    <a href="https://ump-net.cs.columbia.edu/" class="research-proj-title">UMPNet: Universal Manipulation Policy Network for Articulated Objects</a>
                    <p>
                       Zhenjia Xu, Zhanpeng He, Shuran Song<br>
                       Robotics and Automation Letters (RA-L) and ICRA 2022 <br>
                       <a href="https://ump-net.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2109.05668">Paper</a>
                       <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/columbia-ai-robotics/">Code</a> -->
                       
                    </p>
                </div>


                <div class="research-proj">
                    <a href="" class="research-thumb"><img src="images/projects/fish_sim.gif" alt="" /></a>
                    <a href="" class="research-proj-title"> FishGym: A High-Performance Physics-based Simulation Framework for Underwater Robot Learning </a>
                    <p>
                       Wenji Liu, Kai Bai, Xuming He, Shuran Song, Changxi Zheng, and Xiaopei Liu<br>
                       International Conference on Robotics and Automation <b> (ICRA 2022) </b> <br>
                       <a href="https://github.com/fish-gym/gym-fish">Code</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="paper/fish-gym.pdf">Paper</a>
                       <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp; <a href="https://github.com/columbia-ai-robotics/">Code</a> -->
                       
                    </p>
                </div>


                

               

                <div class="research-proj">
                    <a href="" class="research-thumb"><img src="images/projects/se3pose.jpeg" alt="" /></a>
                    <a href="" class="research-proj-title">Leveraging SE(3) Equivariance for Self-supervised Category-Level Object Pose Estimation from Point Clouds </a>
                    <p>
                       Xiaolong Li, Yijia Weng, Li Yi, Leonidas Guibas, A. Lynn Abbott, Shuran Song, He Wang <br>
                       NeurIPS, 2021 <br>
                      
                       <a href="https://dragonlong.github.io/equi-pose/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2111.00190">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/dragonlong/equi-pose">Code</a>
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://flingbot.cs.columbia.edu/" class="research-thumb"><img src="images/projects/flingbot-crop.gif" alt="" /></a>
                    <a href="https://flingbot.cs.columbia.edu/" class="research-proj-title">FlingBot: The Unreasonable Effectiveness of Dynamic Manipulations for Cloth Unfolding</a>
                    <p>
                       Huy Ha, Shuran Song <br>
					   Conference on Robot Learning (<b>CoRL2021</b>)<br>
					   <strong>Best System Paper Award</strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp; <!-- <strong>Oral Presentation</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                       <a href="https://flingbot.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://arxiv.org/abs/2105.03655">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                       <a href="https://github.com/columbia-ai-robotics/flingbot">Code</a>
                       
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://garmentnets.cs.columbia.edu/" class="research-thumb"><img src="images/projects/garmentnets.png" alt="" /></a>
                    <a href="https://garmentnets.cs.columbia.edu/" class="research-proj-title">GarmentNets: Category-Level Pose Estimation for Garments via Canonical Space Shape Completion </a>
                    <p>
                       Cheng Chi, Shuran Song <br>
                       IEEE International Conference on Computer Vision (<b>ICCV2021</b>)<br>
                         <a href="https://garmentnets.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2104.05177">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://github.com/columbia-ai-robotics/garmentnets">Code</a>
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://atp.cs.columbia.edu/" class="research-thumb"><img src="images/projects/atp.png" alt="" /></a>
                    <a href="https://atp.cs.columbia.edu/" class="research-proj-title">Act the Part: Learning Interaction Strategies for Articulated Object Part Discovery </a>
                    <p>
                       Samir Yitzhak Gadre, Kiana Ehsani, Shuran Song <br>
                       IEEE International Conference on Computer Vision (<b>ICCV2021</b>)<br>
                         <a href="https://atp.cs.columbia.edu/">Webpage (with online Demo!)</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2105.01047">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="">Code</a>
                    </p>
                </div>



                <div class="research-proj">
                    <a href="http://crlab.cs.columbia.edu/dynamic_grasping/" class="research-thumb"><img src="images/projects/dynmaic-grasping.png" alt="" /></a>
                    <a href="http://crlab.cs.columbia.edu/dynamic_grasping/" class="research-proj-title">Dynamic Grasping with Reachability and Motion Awareness</a>
                    <p>
                       Iretiayo Akinola*, Jingxi Xu*, Shuran Song, and Peter Allen <br>
                       International Conference on Intelligent Robots and Systems (IROS) 2021<br>
                         <a href="http://crlab.cs.columbia.edu/dynamic_grasping/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2103.10562">Paper</a> 
                       
                    </p>
                </div>


                <div class="research-proj">
                    <a href="https://adagrasp.cs.columbia.edu/" class="research-thumb"><img src="images/projects/adagrasp2.gif" alt="" /></a>
                    <a href="https://adagrasp.cs.columbia.edu/" class="research-proj-title">AdaGrasp: Learning an Adaptive Gripper-Aware Grasping Policy</a>
                    <p>
                       Zhenjia Xu, Beichun Qi, Shubham Agrawal, Shuran Song <br>
                       International Conference on Robotics and Automation <b> (ICRA 2021) </b> <br>
                         <a href="https://adagrasp.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2011.14206">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://github.com/columbia-ai-robotics/adagrasp">Code</a>
                    </p>
                </div>

                

                
                
                <div class="research-proj ">
                    <a href="https://spatial-intention-maps.cs.princeton.edu/" class="research-thumb"><img src="images/projects/sim.jpg" alt="" /></a>
                    <a href="https://spatial-intention-maps.cs.princeton.edu/" class="research-proj-title">Spatial Intention Maps for Multi-Agent Mobile Manipulation</a>
                    <p>
                       Jimmy Wu, Xingyuan Sun, Andy Zeng, Shuran Song, Szymon Rusinkiewicz, Thomas Funkhouser <br>
                       International Conference on Robotics and Automation <b> (ICRA 2021) </b> <br>
                         <a href="https://spatial-intention-maps.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2011.14206">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://github.com/jimmyyhwu/spatial-intention-maps">Code</a>
                    </p>
                </div>

                 <div class="research-proj ">
                    <a href="http://www.cs.columbia.edu/~bchen/vpttob//" class="research-thumb"><img src="images/projects/VPT.jpg" alt="" /></a>
                    <a href="http://www.cs.columbia.edu/~bchen/vpttob/" class="research-proj-title">Visual Perspective Taking for Opponent Behavior Modeling</a>
                    <p>
                       Boyuan Chen, Yuhang Hu, Robert Kwiatkowski, Shuran Song, Hod Lipson <br>
                       International Conference on Robotics and Automation <b> (ICRA 2021) </b> <br>
                         <a href="http://www.cs.columbia.edu/~bchen/vpttob/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2103.12710">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="">Code</a>
                    </p>
                </div>
                
                <div class="research-proj ">
                    <a href="https://sscnav.cs.columbia.edu/" class="research-thumb"><img src="images/projects/SSCNav.gif" alt="" /></a>
                    <a href="https://sscnav.cs.columbia.edu/" class="research-proj-title">SSCNav: Confidence-Aware Semantic Scene Completion for Visual Semantic Navigation</a>
                    <p>
                       Yiqing Liang, Boyuan Chen, Shuran Song <br>
                       International Conference on Robotics and Automation <b> (ICRA 2021) </b> <br>
                         <a href="https://sscnav.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2012.04512">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://github.com/columbia-ai-robotics/SSCNav">Code</a>
                    </p>
                </div>
                
                <div class="research-proj ">
                    <a href="https://dsr-net.cs.columbia.edu/" class="research-thumb"><img src="images/projects/spotlight_dsrnet.jpg" alt="" /></a>
                    <a href="https://dsr-net.cs.columbia.edu/" class="research-proj-title">Learning 3D Dynamic Scene Representations for Robot Manipulation</a>
                    <p>
                       Zhenjia Xu*, Zhanpeng He*, Jiajun Wu, Shuran Song <br>
                       Conference on Robot Learning (CoRL) 2020 <br> 
                        <!-- <strong>Oral Presentation</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                        <a href="https://dsr-net.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2011.01968">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://github.com/columbia-ai-robotics/dsr">Code</a>
                    </p>
                </div>
                
                <div class="research-proj">
                    <a href="https://fit2form.cs.columbia.edu/" class="research-thumb"><img src="images/projects/fit2form.gif" alt="" /></a>
                    <a href="https://fit2form.cs.columbia.edu/" class="research-proj-title">Fit2Form: 3D Generative Model for Robot Gripper Form Design</a>
                    <p>
                       Huy Ha*, Shubham Agrawal*, Shuran Song <br>
                       Conference on Robot Learning (CoRL) 2020 <br> 
                        <!-- <strong>Oral Presentation</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                        <a href="https://fit2form.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2011.06498">Paper</a>
                        <a href="https://github.com/columbia-ai-robotics/fit2form">Code</a>
                    </p>
                </div>

                

                <div class="research-proj ">
                    <a href="https://multiarm.cs.columbia.edu/" class="research-thumb"><img src="images/projects/multiarm.gif" alt="" /></a>
                    <a href="https://multiarm.cs.columbia.edu/" class="research-proj-title">Learning a Decentralized Multi-arm Motion Planner</a>
                    <p>
                       Huy Ha, Jingxi Xu, Shuran Song <br>
                       Conference on Robot Learning (CoRL) 2020 <br> 
                        <!-- <strong>Oral Presentation</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                        <a href="https://multiarm.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/2011.02608">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://github.com/columbia-ai-robotics/decentralized-multiarm">Code</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="" class="research-thumb"><img src="images/projects/ads-eccv2020.jpg" alt="" /></a>
                    <a href="" class="research-proj-title">Multi-task Learning Increases Adversarial Robustness </a>
                    <p>
                        Chengzhi Mao, Amogh Gupta, Vikram Nitin, Baishakhi Ray, Shuran Song, Junfeng Yang, Carl Vondrick<br>
                        European Conference on Computer Vision (ECCV) 2020 <br> 
                        <strong>Oral Presentation</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <!-- <a href="">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                        <a href="https://arxiv.org/abs/2007.07236v1">PDF</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="http://graspinwild.cs.columbia.edu/" class="research-thumb"><img src="images/projects/graspinwild.jpg" alt="" /></a>
                    <a href="http://graspinwild.cs.columbia.edu/" class="research-proj-title">Grasping in the Wild: Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations</a>
                    <p>
                        Shuran Song, Andy Zeng, Johnny Lee, Thomas Funkhouser<br>
                        Intelligent Robots and Systems (IROS) 2020 <br> Robotics and Automation Letters (RA-L) 2020</i><br>
                        <a href="http://graspinwild.cs.columbia.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1912.04344">PDF</a>
                    </p>
                </div>

                

                <div class="research-proj ">
                    <a href="https://spatial-action-maps.cs.princeton.edu/" class="research-thumb"><img src="images/projects/rss20.png" alt="" /></a>
                    <a href="https://spatial-action-maps.cs.princeton.edu/" class="research-proj-title">Spatial Action Maps for Mobile Manipulation</a>
                    <p>
                        Jimmy Wu, Xingyuan Sun, Andy Zeng, Shuran Song, Johnny Lee, Szymon Rusinkiewicz, Thomas Funkhouser<br>
                        Robotics: Science and Systems (RSS) 2020 <br>
                        <a href="https://spatial-action-maps.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/2004.09141.pdf">PDF</a>
                    </p>
                </div>
                
                <div class="research-proj ">
                    <a href="https://articulated-pose.github.io/" class="research-thumb"><img src="images/projects/artpose.jpg" alt="" /></a>
                    <a href="https://articulated-pose.github.io/" class="research-proj-title">Category-Level Articulated Object Pose Estimation</a>
                    <p>
                        Xiaolong Li, He Wang, Li Yi, Leonidas Guibas, A. Lynn Abbott, Shuran Song<br>
                        <i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2020</i><br>
                        <strong>Oral Presentation</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://articulated-pose.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1912.11913">PDF</a>
                    </p>
                </div>
               
                <div class="research-proj">
                    <a href="http://form2fit.github.io/" class="research-thumb"><img src="images/projects/form2fit.png" alt="" /></a>
                    <a href="http://form2fit.github.io/" class="research-proj-title">Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly</a>
                    <p>
                        Kevin Zakka, Andy Zeng, Johnny Lee, Shuran Song<br>
                        International Conference on Robotics and Automation <b> (ICRA 2020) </b> <br>
                        <strong>Best Paper Award in Automation  Finalist</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://form2fit.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1910.13675">PDF</a>
                    </p>
                </div>
                <div class="research-proj">
                    <a href="https://sites.google.com/view/cleargrasp" class="research-thumb"><img src="images/projects/cleargrasp.gif" alt="" /></a>
                    <a href="https://sites.google.com/view/cleargrasp" class="research-proj-title">ClearGrasp: 3D Shape Estimation of Transparent Objects for Manipulation</a>
                    <p>
                        Shreeyak S. Sajjan, Matthew Moore, Mike Pan, Ganesh Nagaraja, Johnny Lee, Andy Zeng, Shuran Song <br>
                        International Conference on Robotics and Automation <b> (ICRA 2020) </b><br>
                        <a href="https://sites.google.com/view/cleargrasp">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1910.02550">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="https://yenchenlin.me/vision2action/" class="research-thumb"><img src="images/projects/vision2action.png" alt="" /></a>
                    <a href="https://yenchenlin.me/vision2action/" class="research-proj-title"> Learning to See before Learning to Act: Visual Pre-training for Manipulation</a>
                    <p>
                        Lin Yen-Chen, Andy Zeng, Shuran Song, Phillip Isola, Tsung-Yi Lin <br>
                        International Conference on Robotics and Automation <b> (ICRA 2020) </b> <br>
                        <a href="https://yenchenlin.me/vision2action/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://yenchenlin.me/vision2action/">PDF</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://tossingbot.cs.princeton.edu/" class="research-thumb"><img src="images/projects/tossing.jpg" alt="" /></a>
                    <a href="https://tossingbot.cs.princeton.edu/" class="research-proj-title"> TossingBot: Learning to Throw Arbitrary Objects with Residual Physics </a>
                    <p>
                        Andy Zeng, Shuran Song, Stefan Welker, Johnny Lee, Alberto Rodriguez, Thomas Funkhouser <br>   
                        Robotics: Science and Systems 2019  <b>(RSS 2019)</b> <br> IEEE Transactions on Robotics   <b>(T-RO 2020)</b> <br>
                        <strong>Best System Paper Award</strong> &nbsp;&nbsp; <strong>Best Student Paper Finalist</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://tossingbot.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://tossingbot.cs.princeton.edu/">PDF</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="http://www.zhenjiaxu.com/DensePhysNet/" class="research-thumb"><img src="images/projects/densephysnet-crop.gif" alt="" /></a>
                    <a href="http://www.zhenjiaxu.com/DensePhysNet/" class="research-proj-title"> DensePhysNet: Learning Dense Physical Object Representations via Multi-step Dynamic Interactions</a>
                    <p>
                        Zhenjia Xu, Jiajun Wu, Andy Zeng, Joshua Tenenbaum, Shuran Song <br>
                        Robotics: Science and Systems 2019 <b>(RSS 2019)</b> <br>  
                        <!-- <strong>Best System Paper Award</strong> &nbsp;&nbsp; <strong>Best Student Paper Finalist</strong>&nbsp;&nbsp;&bull;&nbsp;&nbsp; -->
                        <a href="http://www.zhenjiaxu.com/DensePhysNet/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1906.03853.pdf">PDF</a>
                    </p>
                </div>


                <span id="morePubs">

                <div class="research-proj ">
                    <a href="https://geometry.stanford.edu/projects/NOCS_CVPR2019/" class="research-thumb"><img src="images/projects/PoseRCNN2019.jpg" alt="" /></a>
                    <a href="https://geometry.stanford.edu/projects/NOCS_CVPR2019/" class="research-proj-title">Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation</a>
                    <p>
                        He Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, <b>Shuran Song </b>, Leonidas J. Guibasi<br>
                        Proceedings of 32th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2019</b>)<br> 
                        <strong>Oral Presentation</strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://geometry.stanford.edu/projects/NOCS_CVPR2019/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1906.07370.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="https://illumination.cs.princeton.edu/" class="research-thumb"><img src="images/projects/illumination.png" alt="" /></a>
                    <a href="https://illumination.cs.princeton.edu/" class="research-proj-title">Neural Illumination: Lighting Prediction for Indoor Environments</a>
                    <p>
                        <b>Shuran Song</b> and Thomas Funkhouser<br>
                        Proceedings of 32th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2019</b>)<br>
                        <strong>Oral Presentation</strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://illumination.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1906.07370.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Neural_Graph_Matching_ECCV_2018_paper.pdf" class="research-thumb"><img src="images/projects/graph_learning.jpg" alt="" /></a>
                    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Neural_Graph_Matching_ECCV_2018_paper.pdf" class="research-proj-title">Neural Graph Matching Networks for Fewshot 3D Action Recognition</a>
                    <p>
                        Michelle Guo, Edward Chou, <b>Shuran Song</b>, De-An Huang, Serena Yeung, Li Fei-Fei<br>
                        European Conference on Computer Vision (<b>ECCV2018</b>)<br>
                        <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Neural_Graph_Matching_ECCV_2018_paper.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="http://vpg.cs.princeton.edu/" class="research-thumb"><img src="images/projects/vpg.jpg" alt="" /></a>
                    <a href="http://vpg.cs.princeton.edu/" class="research-proj-title">Learning Synergies between Pushing and Grasping with Self-supervised Deep Reinforcement Learning</a>
                    <p>
                        A. Zeng, <b>S. Song</b>, S. Welker, J. Lee, A. Rodriguez, T. Funkhouser <br>
                        Intelligent Robots and Systems (IROS) 2020 <br> 
                        <strong> Best Cognitive Robotics Paper Award Finalist</strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp; 

                        <a href="https://vpg.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1803.09956.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="http://im2pano3d.cs.princeton.edu/" class="research-thumb"><img src="images/projects/im2pano3d.jpg" alt="" /></a>
                    <a href="http://im2pano3d.cs.princeton.edu/" class="research-proj-title">Im2Pano3D: Extrapolating 360 Structure and Semantics Beyond the Field of View</a>
                    <p>
                        <b>S. Song</b>, A. Zeng, A. X. Chang, M. Savva, S. Savarese, T. Funkhouser <br>
                        Proceedings of 31th IEEE Conference on Computer Vision and Pattern Recognition <b>CVPR2018</b><br> 
                        <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://im2pano3d.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://arxiv.org/abs/1712.04569">PDF</a>
                    </p>
                </div>


                <div class="research-proj">
                    <a href="http://arc.cs.princeton.edu/" class="research-thumb"><img src="images/projects/arc.jpg" alt="" /></a>
                    <a href="http://arc.cs.princeton.edu/" class="research-proj-title">Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching</a>
                    <p>
                       A. Zeng, <b>S. Song</b>, K. Yu, E. Donlon, F. R. Hogan, M. Bauza, D. Ma, O. Taylor, M. Liu, E. Romo, N. Fazeli, F. Alet, N. C. Dafle, R. Holladay, I. Morona, P. Q. Nair, D. Green, I. Taylor, W. Liu, T. Funkhouser, A. Rodriguez   <b>(ICRA2018)</b><br>
                       
                        <strong> Amazon Robotics Best Systems Paper Award </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://arc.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1710.01330.pdf">PDF</a>
                    </p>
                </div>


                 <div class="research-proj ">
                    <a href="http://sscnet.cs.princeton.edu/" class="research-thumb"><img src="images/projects/ssc.jpg" alt="" /></a>
                    <a href="http://sscnet.cs.princeton.edu/" class="research-proj-title">Semantic Scene Completion from a Single Depth Image</a>
                    <p>
                        <b>S. Song</b>, F. Yu, A. Zeng, A. Chang, M. Savva, T. Funkhouser <br>
                        Proceedings of 30th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
                        <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://sscnet.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1611.08974.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="http://3dmatch.cs.princeton.edu/" class="research-thumb"><img src="images/projects/3dmatch.jpg" alt="" /></a>
                    <a href="http://3dmatch.cs.princeton.edu/" class="research-proj-title">3DMatch: Learning the Matching of Local 3D Geometry in Range Scans</a>
                    <p>
                        A. Zeng, <b>S. Song</b>, M. Niener, M. Fisher, J. Xiao and T. Funkhouser.<br>
                        Proceedings of 30th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
                        <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://3dmatch.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2016/3DMatch/paper_v2.pdf">PDF</a>
                    </p>
                    <br>
                </div>

                

                <div class="research-proj ">
                    <a href="http://pbr.cs.princeton.edu/" class="research-thumb"><img src="images/projects/pbr.jpg" alt="" /></a>
                    <a href="http://pbr.cs.princeton.edu/" class="research-proj-title">Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks</a>
                    <p>
                        Y. Zhang<sup>*</sup>, <b>S. Song<sup>*</sup></b>,  E. Yumer, M. Savva, J. Lee, H. Jin, T. Funkhouser.<br>
                        Proceedings of 30th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
                        <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="https://arxiv.org/abs/1612.07429">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/abs/1612.07429">PDF</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="https://niessner.github.io/Matterport/" class="research-thumb"><img src="images/projects/matterport.jpg" alt="" /></a>
                    <a href="https://niessner.github.io/Matterport/" class="research-proj-title">Matterport3D: Learning from RGB-D Data in Indoor Environments</a>
                    <p>
                        A. X. Chang, A. Dai, T. Funkhouser, M. Halber, M. Niener, M. Savva, <b> S. Song </b>, A. Zeng, Y. Zhang<br>
                        IEEE International Conference on 3D Vision  (<b>3DV 2017</b>)<br>
                        <!-- <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;   -->
                        <a href="https://niessner.github.io/Matterport/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1709.06158.pdf">PDF</a>

                    </p>
                    <br>
                </div>


                <div class="research-proj">
                    <a href="http://apc.cs.princeton.edu" class="research-thumb"><img src="images/projects/robot.png" alt="" /></a>
                    <a href="http://apc.cs.princeton.edu" class="research-proj-title">Multi-view Self-supervised Deep Learning for 6D Pose Estimation in the Amazon Picking Challenge</a>
                    <p>
                        A. Zeng, K.T. Yu, <b>S. Song</b>, D. Suo, E. Walker Jr., A. Rodriguez, and J. Xiao<br>
                        International Conference on Robotics and Automation (<b>ICRA2017</b>) <br>
                       <!--  <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;   -->
                        <a href="http://apc.cs.princeton.edu">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="https://arxiv.org/pdf/1609.09475v1.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj">
                    <a href="http://apc.cs.princeton.edu" class="research-thumb"><img src="images/projects/thumbnail(4).jpg" alt="" /></a>
                    <a href="http://apc.cs.princeton.edu" class="research-proj-title">Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images</a>
                    <p>
                        <b>S. Song</b>, and J. Xiao.<br>
                        Proceedings of 29th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2016</b>)<br>
                       <!--  <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;   -->
                        <a href="http://dss.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2015/DSS/paper.pdf">PDF</a>
                    </p>
                    <br>
                </div>


                <div class="research-proj">
                    <a href="http://shapenet.org/" class="research-thumb"><img src="images/projects/shapenet.jpg" alt="" /></a>
                    <a href="http://shapenet.org/" class="research-proj-title">ShapeNet: An Information-Rich 3D Model Repository</a>
                    <p>
                        A. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, <b>S. Song</b>, H. Su, J. Xiao, L. Yi, and F. Yu.<br>
                        arXiv:1512.03012 [cs.CV] 9 Dec 2015<br>
                       <!--  <strong> Oral Presentation </strong> &nbsp;&nbsp;&bull;&nbsp;&nbsp;   -->
                        <a href="http://shapenet.org/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2015/ShapeNet/paper.pdf">PDF</a>
                    </p>
                </div>



                <div class="research-proj">
                    <a href="http://rgbd.cs.princeton.edu/" class="research-thumb"><img src="images/projects/sunrgbd.jpg" alt="" /></a>
                    <a href="http://rgbd.cs.princeton.edu/" class="research-proj-title">SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite</a>
                    <p>
                        <b>S. Song</b>, S. Lichtenberg and J. Xiao<br>
                        Proceedings of 28th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2015</b>)<br>
                        <a style="color: #005C91;" href="http://techtalks.tv/talks/sun-rgb-d-a-rgb-d-scene-understanding-benchmark-suite/61578/">  <strong> Oral Presentation [Watch it on Techtalks] </strong> </a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="http://rgbd.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2015/SUNrgbd/paper.pdf">PDF</a>
                    </p>
                </div>


                <div class="research-proj">
                    <a href="http://3dshapenets.cs.princeton.edu/" class="research-thumb"><img src="images/projects/3dshapenet.jpg" alt="" /></a>
                    <a href="http://3dshapenets.cs.princeton.edu/" class="research-proj-title">SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite</a>
                    <p>
                        Z. Wu, <b>S. Song</b>, A. Khosla, F. Yu, L. Zhang, X. Tang and J. Xiao<br>
                        Proceedings of 28th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2015</b>)<br>
                        <a style="color: #005C91;" href="http://techtalks.tv/talks/3d-shapenets-a-deep-representation-for-volumetric-shapes/61589/">  <strong> Oral Presentation [Watch it on Techtalks] </strong> </a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="http://3dshapenets.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2014/3DShapeNets/paper.pdf">PDF</a>
                    </p>
                </div>

                <div class="research-proj ">
                    <a href="http://vision.princeton.edu/projects/2015/RobotInARoom/" class="research-thumb"><img src="images/projects/thumbnail(8).jpg" alt="" /></a>
                    <a href="http://vision.princeton.edu/projects/2015/RobotInARoom/" class="research-proj-title">Robot In a Room: Toward Perfect Object Recognition in Closed Environments</a>
                    <p>
                        <b>S. Song</b>, L. Zhang, and J. Xiao.<br>
                        arXiv:1507.02703 [cs.CV] 9 Jul 2015<br>
                        <a href="http://vision.princeton.edu/projects/2015/RobotInARoom/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2015/RobotInARoom/paper.pdf">PDF</a>
                    </p>
                </div>


                <div class="research-proj ">
                    <a href="http://lsun.yf.io/" class="research-thumb"><img src="images/projects/lsun.jpg" alt="" /></a>
                    <a href="http://lsun.yf.io/" class="research-proj-title">Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop</a>
                    <p>
                        F. Yu,  A. Seff,  Y. Zhang, <b>S. Song</b> and J. Xiao.<br>
                        arXiv:1506.03365 [cs.CV] 10 Jun 2015<br>
                        <a href="http://lsun.yf.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://arxiv.org/abs/1506.03365">PDF</a>
                    </p>
                </div>
                
                <div class="research-proj">
                    <a href="http://slidingshapes.cs.princeton.edu/" class="research-thumb"><img src="images/projects/thumbnail(10).jpg" alt="" /></a>
                    <a href="http://slidingshapes.cs.princeton.edu/" class="research-proj-title">Sliding Shapes for 3D Object Detection in Depth Images</a>
                    <p>
                        <b>S. Song</b> and J. Xiao<br>
                        Proceedings of the 13th European Conference on Computer Vision (<b>ECCV2014</b>)<br>
                        <a style="color: #005C91;" href="http://videolectures.net/eccv2014_song_depth_images/">  <strong> Oral Presentation [Watch it on Videolectures] </strong> </a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="http://slidingshapes.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2014/SlidingShapes/paper.pdf">PDF</a>
                    </p>
                    <br>
                </div>


                <div class="research-proj ">
                    <a href="http://slidingshapes.cs.princeton.edu/" class="research-thumb"><img src="images/projects/thumbnail(11).jpg" alt="" /></a>
                    <a href="http://slidingshapes.cs.princeton.edu/" class="research-proj-title">PanoContext: A Whole-room 3D Context Model for Panoramic Scene Understanding</a>
                    <p>
                        Y. Zhang, <b>S. Song</b>, P. Tan, and J. Xiao<br>
                        Proceedings of the 13th European Conference on Computer Vision (<b>ECCV2014</b>)<br>
                        <a style="color: #005C91;" href="http://videolectures.net/eccv2014_song_depth_images/">  <strong> Oral Presentation [Watch it on Videolectures] </strong> </a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;  
                        <a href="http://panocontext.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2014/PanoContext/paper.pdf">PDF</a>
                    </p>
                    <br>
                </div>


                <div class="research-proj ">
                    <a href="http://tracking.cs.princeton.edu/" class="research-thumb"><img src="images/projects/tracking.jpg" alt="" /></a>
                    <a href="http://tracking.cs.princeton.edu/" class="research-proj-title">Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines</a>
                    <p>
                         <b>S. Song</b> and J. Xiao<br>
                         Proceedings of 14th IEEE International Conference on Computer Vision (<b>ICCV2013</b>)<br>
                        <a href="http://tracking.cs.princeton.edu/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="http://3dvision.princeton.edu/projects/2013/tracking/paper.pdf">PDF</a>
                    </p>
                </div>


                </span>

                <div onclick="togglePubs()" id="morePubsBtn" class="showBtn"><a>Show more...</a></div>
                <div onclick="togglePubs()" id="lessPubsBtn" class="showBtn"><a>Show less...</a></div>
                <div style="clear: both;"></div>
            </div>

            <div class="divider"></div>
            <div class="section tesching">
            <h1>Teaching</h1>
                <p>
                    <ul>
                        <li><a href="https://sites.google.com/view/spring2022-coms4733/home">COMS 4733 Computational Aspects of Robotics,2022</a> </li>
                        <li><a href="https://sites.google.com/view/robot-learning-2019fall/home">COMS 6998 Topics in Robot Learning, 2021</a> </li>
                        <li><a href="https://sites.google.com/view/coms4733-fall2020/home">COMS 4733 Computational Aspects of Robotics, 2020</a> </li>
                        <li><a href="https://sites.google.com/view/robot-learning-2019fall/home">COMS 6998 Topics in Robot Learning</a> </li>
                        <li>Teaching Assistant: <a href="http://www.cs.princeton.edu/courses/archive/spr15/cos126/syllabus.html">Princeton COS126 General Computer Science</a>, 2015</li>
                        <li>Teaching Assistant: <a href="https://sites.google.com/view/sqml/teaching-experience/elec1100-introduction-to-electro-robot-design"> HKUST ELEC1100 Introduction to Electro-Robot Design </a>, 2011,2012</li>
                        <li>Teaching Assistant: HKUST ELEC1200A System View of Communications: from Signals to Packets, 2011</li>
                    </ul>
                </p>
            </div>

            <div class="divider"></div>
            <!-- <div class="section sponsors">
                <h1>Sponsors</h1>
                <div class="sponsor-thumb">
                    <a href="https://www.tri.global/"><img src="images/sponsors/toyota-research-institute.jpg" alt="" /></a>
                    <a href="https://www.amazonrobotics.com/"><img src="images/sponsors/amazon-robotics.jpg" alt="" /></a>
                    <a href="https://ai.google/"><img src="images/sponsors/google-ai.png" alt="" /></a>
                    <a href=""><img src="images/sponsors/NSF_4-Color_bitmap_Logo.png" alt="" /></a>
                </div>
                <div style="clear: both;"></div> -->
            </div>
        </div>

        <script>
            function toggleNews() {
              var moreNews = document.getElementById("moreNews");
              var moreNewsBtn = document.getElementById("moreNewsBtn");
              var lessNewsBtn = document.getElementById("lessNewsBtn");
              if (moreNewsBtn.style.display === "none") {
                moreNews.style.display = "none";
                moreNewsBtn.style.display = "inline";
                lessNewsBtn.style.display = "none";
              } else {
                moreNews.style.display = "inline";
                moreNewsBtn.style.display = "none";
                lessNewsBtn.style.display = "inline";
              }
            }


            function toggleTalks() {
              var moreTalks = document.getElementById("moreTalks");
              var moreTalksBtn = document.getElementById("moreTalksBtn");
              var lessTalksBtn = document.getElementById("lessTalksBtn");
              
              if (moreTalksBtn.style.display === "none") {
                moreTalks.style.display = "none";
                moreTalksBtn.style.display = "inline";
                lessTalksBtn.style.display = "none";
              } else {
                moreTalks.style.display = "inline";
                moreTalksBtn.style.display = "none";
                lessTalksBtn.style.display = "inline";
              }
            }
            function togglePubs() {
              var morePubs = document.getElementById("morePubs");
              var morePubsBtn = document.getElementById("morePubsBtn");
              var lessPubsBtn = document.getElementById("lessPubsBtn");
              if (morePubsBtn.style.display === "none") {
                morePubs.style.display = "none";
                morePubsBtn.style.display = "inline";
                lessPubsBtn.style.display = "none";
              } else {
                morePubs.style.display = "inline";
                morePubsBtn.style.display = "none";
                lessPubsBtn.style.display = "inline";
              }
            }

            function showRep() {
              var repBtn = document.getElementById("repBtn");
              var showAllBtn = document.getElementById("showAllBtn");
              repBtn.style.color = "#49bf9d";
              repBtn.style.borderBottom = "1px solid #a4dfce";
              showAllBtn.style.color = "#191e3f";
              showAllBtn.style.borderBottom = "none";
              var  = document.getElementsByClassName("");
              for (var i = 0; i < .length; i++) {
                .item(i).style.display = "none";
              }
            }

            function hideRep() {
              var repBtn = document.getElementById("repBtn");
              var showAllBtn = document.getElementById("showAllBtn");
              repBtn.style.color = "#191e3f";
              repBtn.style.borderBottom = "none";
              showAllBtn.style.color = "#49bf9d";
              showAllBtn.style.borderBottom = "1px solid #a4dfce";
              var  = document.getElementsByClassName("");
              for (var i = 0; i < .length; i++) {
                .item(i).style.display = "table";
              }
            }
        </script>
    </body>
</html>